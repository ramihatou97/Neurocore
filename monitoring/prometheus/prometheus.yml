# Prometheus Configuration for Neurocore Monitoring
# Collects metrics from application, containers, and system resources

global:
  scrape_interval: 15s           # Scrape targets every 15 seconds
  evaluation_interval: 15s       # Evaluate rules every 15 seconds
  scrape_timeout: 10s            # Timeout for scrape requests
  external_labels:
    cluster: 'neurocore'
    environment: 'production'

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - alertmanager:9093

# Load alerting rules
rule_files:
  - 'alerts.yml'

# Scrape configurations
scrape_configs:
  # ==================== Prometheus Self-Monitoring ====================
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
        labels:
          service: 'prometheus'
          tier: 'monitoring'

  # ==================== Application - FastAPI Backend ====================
  - job_name: 'neurocore-api'
    metrics_path: '/api/v1/performance/metrics'
    scrape_interval: 10s
    static_configs:
      - targets: ['api:8000']
        labels:
          service: 'neurocore-api'
          tier: 'application'
          component: 'backend'

  # ==================== Database - PostgreSQL ====================
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']
        labels:
          service: 'postgres'
          tier: 'database'
    # Optional: Add postgres_exporter container to docker-compose.monitoring.yml
    # if you want detailed PostgreSQL metrics

  # ==================== Cache - Redis ====================
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
        labels:
          service: 'redis'
          tier: 'cache'
    # Optional: Add redis_exporter container to docker-compose.monitoring.yml
    # if you want detailed Redis metrics

  # ==================== Task Queue - Celery ====================
  - job_name: 'celery'
    static_configs:
      - targets: ['celery-exporter:9808']
        labels:
          service: 'celery'
          tier: 'workers'
    # Optional: Add celery-exporter for worker metrics

  # ==================== System Metrics - Node Exporter ====================
  - job_name: 'node-exporter'
    scrape_interval: 30s
    static_configs:
      - targets: ['node-exporter:9100']
        labels:
          service: 'node-exporter'
          tier: 'infrastructure'
          component: 'host'

  # ==================== Container Metrics - cAdvisor ====================
  - job_name: 'cadvisor'
    scrape_interval: 30s
    static_configs:
      - targets: ['cadvisor:8080']
        labels:
          service: 'cadvisor'
          tier: 'infrastructure'
          component: 'containers'

  # ==================== Monitoring Stack - Grafana ====================
  - job_name: 'grafana'
    static_configs:
      - targets: ['grafana:3000']
        labels:
          service: 'grafana'
          tier: 'monitoring'

  # ==================== Log Aggregation - Loki ====================
  - job_name: 'loki'
    static_configs:
      - targets: ['loki:3100']
        labels:
          service: 'loki'
          tier: 'monitoring'

  # ==================== Frontend - Nginx (if exporter available) ====================
  # - job_name: 'nginx'
  #   static_configs:
  #     - targets: ['nginx-exporter:9113']
  #       labels:
  #         service: 'nginx'
  #         tier: 'frontend'

# Remote write configuration (optional - for long-term storage)
# remote_write:
#   - url: "https://prometheus-remote-storage.example.com/api/v1/write"
#     basic_auth:
#       username: "user"
#       password: "password"

# Remote read configuration (optional)
# remote_read:
#   - url: "https://prometheus-remote-storage.example.com/api/v1/read"
#     basic_auth:
#       username: "user"
#       password: "password"
